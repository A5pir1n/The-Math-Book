\documentclass[../main.tex]{subfiles}
% \graphicspath{{\subfix{../figures/}}}
\begin{document}
\section{Vector Spaces}
Loosely speaking, linear algebra is a branch of mathematics which studies common properties of a algebraic system. This system consists of a set and some notion of an operation, that is the ``linear combination" of the elements in the set. 

So called vector space turned out to one of the most useful abstraction of this type of algebraic system. 
\begin{definition}
    A vector space (or linear space) consists of the following:
    \begin{enumerate}
        \item a field $F$ of scalars;
        \item a set $V$ of objects, called vectors;
        \item a rule (or operation), called vector addition, which associates with each pair of vectors $\alpha, \beta$ in $V$ a vector $\alpha+\beta$ in $V$, called the sum of $\alpha$ and $\beta$, in such a way that
        \begin{enumerate}[a.]
            \item addition is commutative, $\alpha+\beta=\beta+\alpha$;
            \item addition is associative, $\alpha+(\beta+\gamma)=(\alpha+\beta)+\gamma$;
            \item there is a unique vector 0 in $V$, called the zero vector, such that $\alpha+0=\alpha$ for all $\alpha$ in $V$;
            \item for each vector $\alpha$ in $V$ there is a unique vector $-\alpha$ in $V$ such that $\alpha+(-\alpha)=0$;
        \end{enumerate}
        \item a rule (or operation), called scalar multiplication, which associates with each scalar $c$ in $\mathrm{F}$ and vector $\alpha$ in $V$ a vector $c \alpha$ in $V$, called the product of $c$ and $\alpha$, in such a way that
        \begin{enumerate}[a.]
            \item $1 \alpha=\alpha$ for every $\alpha$ in $V$;
            \item $\left(c_1 c_2\right) \alpha=c_1\left(c_2 \alpha\right)$;
            \item $c(\alpha+\beta)=c \alpha+c \beta$;
            \item $\left(c_1+c_2\right) \alpha=c_1 \alpha+c_2 \alpha$.
        \end{enumerate}
    \end{enumerate}
\end{definition}
When we associate a vector space $V$ with a field $F$, we say $V$ is a \textbf{vector space over the field} $F$. It is important note that the vectors in a vector space is much more general than the vectors we encounter in elementary algebra, which is just a special case in our more general vector space. We call it the \textbf{$n$-tuple space} and we show more examples of other vector spaces below. 

\begin{example}The $n$-tuple space, $F^n$. Let $F$ be any field, and let $V$ be the set of all $n$-tuples $\alpha=\left(x_1, x_2, \ldots, x_n\right)$ of scalars $x_i$ in $F$. If $\beta=$ $\left(y_1, y_2, \ldots, y_n\right)$ with $y_i$ in $F$, the sum of $\alpha$ and $\beta$ is defined by
$$\quad \alpha+\beta=\left(x_1+y_1, x_2+y_2, \ldots, x_n+y_n\right).$$
The product of a scalar $c$ and vector $\alpha$ is defined by
$$\quad c \alpha=\left(c x_1, c x_2, \ldots, c x_n\right).$$
The fact that this vector addition and scalar multiplication satisfy conditions (3) and (4) is easy to verify, using the similar properties of addition and multiplication of elements of $F$.
\end{example}
\begin{example}
The space of $m \times n$ matrices, $F^{m \times n}$. Let $F$ be any field and let $m$ and $n$ be positive integers. Let $F^{m \times n}$ be the set of all $m \times n$ matrices over the field $F$. The sum of two vectors $A$ and $B$ in $F^{m \times n}$ is defined by
$$
(A+B)_{i j}=A_{i j}+B_{i j} .
$$
\end{example}

\section{Norms and normed vector spaces}

\begin{definition}
For a vector space $V$ over field $F$ with element $x \in V$, a \textbf{norm} of $V$ is a function $\norm{x}: V \rightarrow [0,\infty)$ satisfying: 
\begin{enumerate}
    \item $\norm{x} = 0$ if and only if $x = 0$.
    \item (Triangle inequality.) $\norm{x + y} \leq \norm{x} + \norm{y}$ for every $x, y \in V$. 
    \item $\norm{cx} = \abs{c} \cdot \norm{x}$ for every $c \in F$ and $x \in V$. 
\end{enumerate}
\end{definition}


\begin{definition}
A pair $(V, \norm{\,\cdot \,})$ where $V$ is a vector space and $\norm{\, \cdot \,}$ is a norm on $V$ is a \textbf{normed vector space}.
\end{definition}


\subsection{Operator Norms}
The operator norms allows us to measure the 
``size'' of a norm in terms of how much the operator is capable of ``stretching" an argument.
\begin{definition}
For a normed vectors spaces $X = (U,\norm{\, \cdot \,}_U)$ and $Y = (V,\norm{\, \cdot \,}_V)$, we set
\begin{equation}
    \mathcal{L}(X,Y) = \{ T: X \rightarrow Y | T  \text{ is linear and continuous} \},
\end{equation}
and put $\mathcal{L}(X,X) = \mathcal{L}(X)$. The dual space of $\mathcal{L}(X,\mathbb{F})$ of $X$ is denoted by $X^\star$. An element $x^\star \in X^\star$ is called a \textbf{linear functional} on $X$, and one often write $\langle x,x^\star \rangle$ instead of $x^\star (x)$.

For $T \in \mathcal{L}(X,Y)$ the \textbf{operator norm} is defined as 
\begin{align}
    \norm{T}_{\mathcal{L}(X,Y)} = \norm{T}_{op}
    &= \inf\{(c \leq 0 |\, \forall x \in X \text{ we have } \norm{Tx}_Y \leq c \norm{x}_X \} < \infty \\
    &= \sup\left\{ \frac{\norm{Tx}_Y}{\norm{x}_X } \, | \, x \in X \right\}.
\end{align}
\end{definition}

\begin{prop}
TO be filled
\end{prop}

\subsubsection{Applications}
\paragraph{Approximation Theory}
This is a very useful notion for approximation theory in the situation where our approximation to the element $f$ can be described as applying an operator $T$ to $f$ to obtain the approximation $T(f)$.

\subsection{Continuity and differentiablility}
\begin{definition}
Let $X = (U,\norm{\, \cdot \,}_U)$ and $Y = (V,\norm{\, \cdot \,}_V)$ be vector spaces. Given a $\Omega \subseteq X$ and a function $T \, : \, \Omega \rightarrow Y$, we say that $T$ is \textbf{continuous at a point $x_0 \in \Omega$} if for every $\varepsilon > 0$ there exists $\delta > 0$ such that a $x \in \Omega$ with $\norm{x - x_0}_U \leq \delta$ implies that $\norm{T(x) - T(x_0)}_V \leq \varepsilon$. We say that $T$ is \textbf{continuous} if it is continuous at every point of $\Omega$. 
We say that a function $T$ is \textbf{differentiable} at $x \in \Omega$ if there exists a linear map $D(T(x)) : U \rightarrow V$ such that 
\begin{equation}
    \lim_{x \rightarrow x_0} \frac{\norm{T(x) - T(x_0) - D(T(x))(x - x_0)}_V}{\norm{x - x_0}_U} = 0, 
\end{equation}
and say that $T$ is differentiable if it is differentiable at every point of $\Omega$ in which case $DT$ defines a function $DT:\Omega \rightarrow \mathbb{L}(U, V)$. 
\end{definition}



\begin{prop}

\end{prop}
\end{document}